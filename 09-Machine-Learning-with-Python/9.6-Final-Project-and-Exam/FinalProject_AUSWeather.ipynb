{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de68de1-e4e7-4451-b77a-8bf5aaa28a9f",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Final Project: Building a Rainfall Prediction Classifier\n",
    "Estimated time needed: **60** minutes\n",
    "    \n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "* Explore and perform feature engineering on a real-world data set\n",
    "* Build a classifier pipeline and optimize it using grid search cross validation\n",
    "* Evaluate your model by interpreting various performance metrics and visualizations\n",
    "* Implement a different classifier by updating your pipeline\n",
    "* Use an appropriate set of parameters to search over in each case\n",
    "\n",
    "## Instruction(s)\n",
    "\n",
    "After completing the Notebook:\n",
    "\n",
    "* Download the notebook using **File** > **Download**.\n",
    "* This notebook will be then graded using **AI grader** in the subsequent section.\n",
    "* Copy/Paste your markdown responses in the subsequent **AI Mark assignment**. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6a374-7ce3-4548-9260-b192b29b8050",
   "metadata": {},
   "source": [
    "# About The Dataset\n",
    "The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n",
    "\n",
    "The dataset you'll use in this project was downloaded from Kaggle at [https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package/](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package?resource=download&select=weatherAUS.csv)  \n",
    "Column definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)  \n",
    "\n",
    "The dataset contains observations of weather metrics for each day from 2008 to 2017, and includes the following fields:\n",
    "\n",
    "| Field         | Description                                           | Unit            | Type   |\n",
    "| :------------ | :---------------------------------------------------- | :-------------- | :----- |\n",
    "| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n",
    "| Location      | Location of the Observation                           | Location        | object |\n",
    "| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n",
    "| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n",
    "| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n",
    "| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n",
    "| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n",
    "| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n",
    "| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n",
    "| WindDir9am    | Wind direction averaged over 10 minutes prior to 9am  | Compass Points  | object |\n",
    "| WindDir3pm    | Wind direction averaged over 10 minutes prior to 3pm  | Compass Points  | object |\n",
    "| WindSpeed9am  | Wind speed averaged over 10 minutes prior to 9am      | Kilometers/Hour | float  |\n",
    "| WindSpeed3pm  | Wind speed averaged over 10 minutes prior to 3pm      | Kilometers/Hour | float  |\n",
    "| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n",
    "| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n",
    "| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n",
    "| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n",
    "| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n",
    "| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n",
    "| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n",
    "| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n",
    "| RainToday     | If there was at least 1mm of rain today               | Yes/No          | object |\n",
    "| RainTomorrow  | If there is at least 1mm of rain tomorrow             | Yes/No          | object |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15144337-160c-4456-aeaa-5363463a5758",
   "metadata": {},
   "source": [
    "## Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f4307-42a3-4960-88c5-e466f48113ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5a7578-beac-4c9e-b78d-7fcf28623f8e",
   "metadata": {},
   "source": [
    "## Load the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55444382-5385-4e10-9811-6270f8562574",
   "metadata": {},
   "source": [
    "Execute the following cells to load the dataset as a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56a1bb-c7fd-4b91-beab-ef522a1ae425",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/_0eYOqji3unP1tDNKWZMjg/weatherAUS-2.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae135dc-ca25-44c3-8411-093def3f54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf2f9f-5c5b-4bfb-a3ae-8332aa6caf5f",
   "metadata": {},
   "source": [
    "Sunshine and cloud cover seem like important features, but they have a lot of missing values, far too many to impute their missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f6d85-6ec4-42f8-a216-213fa4d0e972",
   "metadata": {},
   "source": [
    "### Drop all rows with missing values\n",
    "To try to keep things simple we'll drop rows with missing values and see what's left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9cf4f-7908-4a77-90ed-6755ed3aef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff9b629-f59f-49ea-b328-5f6f8108ab00",
   "metadata": {},
   "source": [
    "Since we still have 56k observations left after dropping missing values, we may not need to impute any missing values.  \n",
    "Let's see how we do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292c2e5-5d13-432d-9768-5ccf472e148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed889ed7-8186-4514-8a18-b51b96de628e",
   "metadata": {},
   "source": [
    "## Data leakage considerations\n",
    "Consider the descriptions above for the columns in the data set. Are there any practical limitations to being able to predict whether it will rain tomorrow given the available data? \n",
    "\n",
    "## Points to note - 1\n",
    "List some of the features that would be inefficient in predicting tomorrow's rainfall. There will be a question in the quiz that follows based on this observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d9481-f686-4161-9c5b-6552062eaf3e",
   "metadata": {},
   "source": [
    "<details><summary>Click here for Hint</summary>\n",
    "        \n",
    "Consider features that rely on the entire duration of today for their evaluation.     \n",
    "    \n",
    "</details> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8eb64-9251-4e6f-9f5f-b9da65d7dbcd",
   "metadata": {},
   "source": [
    "If we adjust our approach and aim to predict today’s rainfall using historical weather data up to and including yesterday, then we can legitimately utilize all of the available features. This shift would be particularly useful for practical applications, such as deciding whether you will bike to work today.\n",
    "\n",
    "With this new target, we should update the names of the rain columns accordingly to avoid confusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579be81d-61e2-411d-a979-f856f8467d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'RainToday': 'RainYesterday',\n",
    "                        'RainTomorrow': 'RainToday'\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaefc68-2894-4085-b788-56db552491a4",
   "metadata": {},
   "source": [
    "## Data Granularity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76f919-95c1-4105-9ebc-ac602dd59310",
   "metadata": {},
   "source": [
    "Would the weather patterns have the same predictability in vastly different locations in Australia? I would think not.  \n",
    "The chance of rain in one location can be much higher than in another. \n",
    "Using all of the locations requires a more complex model as it needs to adapt to local weather patterns.  \n",
    "Let's see how many observations we have for each location, and see if we can reduce our attention to a smaller region.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a9b5b-1719-4505-8d43-ab0cb1f520e6",
   "metadata": {},
   "source": [
    "## Location selection\n",
    "You could do some research to group cities in the `Location` column by distance, which I've done for you behind the scenes.  \n",
    "I found that Watsonia is only 15 km from Melbourne, and the Melbourne Airport is only 18 km from Melbourne.  \n",
    "Let's group these three locations together and use only their weather data to build our localized prediction model.  \n",
    "Because there might still be some slight variations in the weather patterns we'll keep `Location` as a categorical variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46435fb-e0fe-411e-93c7-7cd3f301565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Location.isin(['Melbourne','MelbourneAirport','Watsonia',])]\n",
    "df. info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988aa384-6052-43d3-a7fb-e5d9384e10df",
   "metadata": {},
   "source": [
    "We still have 7557 records, which should be enough to build a reasonably good model.  \n",
    "You could always gather more data if needed by partioning the data into similar locations or simplyby updating it from the source to include a larger time frame.\n",
    "\n",
    "## Extracting a seasonality feature\n",
    "Now consider the `Date` column. We expect the weather patterns to be seasonal, having different predictablitiy levels in winter and summer for example.  \n",
    "There may be some variation with `Year` as well, but we'll leave that out for now.\n",
    "Let's engineer a `Season` feature from `Date` and drop `Date` afterward, since it is most likely less informative than season. \n",
    "An easy way to do this is to define a function that assigns seasons to given months, then use that function to transform the `Date` column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca3b0d-990f-4278-bbc4-536600746b97",
   "metadata": {},
   "source": [
    "### Create a function to map dates to seasons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b52ba-659f-4947-be19-d2e020cc6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_season(date):\n",
    "    month = date.month\n",
    "    if (month == 12) or (month == 1) or (month == 2):\n",
    "        return 'Summer'\n",
    "    elif (month == 3) or (month == 4) or (month == 5):\n",
    "        return 'Autumn'\n",
    "    elif (month == 6) or (month == 7) or (month == 8):\n",
    "        return 'Winter'\n",
    "    elif (month == 9) or (month == 10) or (month == 11):\n",
    "        return 'Spring'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac716e-764a-411c-be4d-6b2a6f5b414e",
   "metadata": {},
   "source": [
    "## Exercise 1: Map the dates to seasons and drop the Date column\n",
    "Complete the code:\n",
    "```python\n",
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(...)\n",
    "\n",
    "# Apply the function to the 'Date' column\n",
    "df['Season'] = df['Date'].apply(date_to_season)\n",
    "\n",
    "df=df.drop(columns=...)\n",
    "df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13bb32a-4343-4341-a9f9-8db65cdfb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Apply the function to the 'Date' column\n",
    "df['Season'] = df['Date'].apply(date_to_season)\n",
    "\n",
    "df = df.drop(columns='Date')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1574d1-4358-43b8-a056-824a3de3c360",
   "metadata": {},
   "source": [
    "Looks like we have a good set of features to work with. \n",
    "\n",
    "Let's go ahead and build our model.\n",
    "\n",
    "But wait, let's take a look at how well balanced our target is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27731ccf-f6a6-4dfd-a009-73e9a5aa0a79",
   "metadata": {},
   "source": [
    "## Exercise 2. Define the feature and target dataframes\n",
    "Complete the followng code:  \n",
    "```python\n",
    "X = df.drop(columns='...', axis=1)\n",
    "y = df['...']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700d181-a76c-494e-a396-c59fa63b4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X as all columns except 'RainToday' which is our target\n",
    "X = df.drop(columns='RainToday', axis=1)\n",
    "y = df['RainToday']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006f481-ad4e-4ed9-ba8c-8cbf5e54baf0",
   "metadata": {},
   "source": [
    "## Exercise 3. How balanced are the classes?\n",
    "Display the counts of each class.\n",
    "\n",
    "Complete the following code:\n",
    "```python\n",
    "... .value_counts()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f238ce-182a-49b1-846a-f445311217e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78db0a-eb2c-41d3-b09f-a80f2cfc4b69",
   "metadata": {},
   "source": [
    "## Exercise 4. What can you conclude from these counts?\n",
    "- How often does it rain annualy in the Melbourne area?\n",
    "- How accurate would you be if you just assumed it won't rain every day?\n",
    "- Is this a balanced dataset?\n",
    "- Next steps?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684001af-b300-4b45-8d01-e602d6e34822",
   "metadata": {},
   "source": [
    "Based on the value counts of the target variable:\n",
    "\n",
    "1. Rainfall frequency:\n",
    "    - \"No\" rain days occur more frequently (approximately 77% of days)\n",
    "    - It rains around 23% of days in the Melbourne area\n",
    "\n",
    "2. Baseline accuracy:\n",
    "    - Simply predicting \"No rain\" every day would give ~77% accuracy\n",
    "    - This forms a strong baseline to compare our models against\n",
    "\n",
    "3. Class imbalance:\n",
    "    - The dataset is imbalanced with a roughly 77:23 split\n",
    "    - \"No rain\" class dominates significantly over \"Rain\" class\n",
    "\n",
    "4. Recommended next steps:\n",
    "    - Consider using class weights or sampling techniques to handle imbalance\n",
    "    - Evaluate models using metrics beyond accuracy (e.g. precision, recall, F1)\n",
    "    - Pay special attention to the minority class performance\n",
    "    - Potentially use techniques like SMOTE for balancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2ac5e-d91b-4bae-8533-de881559430c",
   "metadata": {},
   "source": [
    "## Exercise 5. Split data into training and test sets, ensuring target stratification\n",
    "\n",
    "Complete the followng code:\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(..., ..., test_size=0.2, stratify=..., random_state=42)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5f05b-12b1-4f55-9183-841273b84ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets with stratification on target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a99c9-dba6-4a26-85eb-3ae8f6274781",
   "metadata": {},
   "source": [
    "## Define preprocessing transformers for numerical and categorical features\n",
    "## Exercise 6. Automatically detect numerical and categorical columns and assign them to separate numeric and categorical features\n",
    "\n",
    "Complete the followng code:\n",
    "```python\n",
    "numeric_features = X_train.select_dtypes(include=['...']).columns.tolist()  \n",
    "categorical_features = X_train.select_dtypes(include=['...', 'category']).columns.tolist()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078de85-2496-43c7-b71e-dffbf8cbab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response.\n",
    "numeric_features = X_train.select_dtypes(include=['float64']).columns.tolist()  \n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e50d64-34b4-49a5-b3e1-1dce80df5cc9",
   "metadata": {},
   "source": [
    "### Define separate transformers for both feature types and combine them into a single preprocessing transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab80fe-4c8c-4b1e-81ed-2afdfac57223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numeric features\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# One-hot encode the categoricals \n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e490cc7-ab91-40c0-a5ce-2d1dfbd552c8",
   "metadata": {},
   "source": [
    "## Exercise 7. Combine the transformers into a single preprocessing column transformer\n",
    "Complete the followng code:  \n",
    "```python\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, ...),\n",
    "        ('cat', categorical_transformer, ...)\n",
    "    ]\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e96c5-811a-4845-966c-d109952aa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a21e64-889c-455b-9cb1-4cae6cebf4b4",
   "metadata": {},
   "source": [
    "## Exercise 8. Create a pipeline by combining the preprocessing with a Random Forest classifier\n",
    "Complete the following code:\n",
    "```python\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', ...),\n",
    "    ('...', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbfd286-d210-4db1-8e80-71887b17d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response.\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0af138-bd2a-4044-a5d7-6a2d4957fdc0",
   "metadata": {},
   "source": [
    "### Define a parameter grid to use in a cross validation grid search model optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042eddf8-87ab-43ae-8a5b-b7aaf861153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fa6af-f1b1-4556-8260-2d3090a594fa",
   "metadata": {},
   "source": [
    "### Pipeline usage in crossvalidation\n",
    "Recall that the pipeline is repeatedly used within the crossvalidation by fitting on each internal training fold and predicting on its corresponding validation fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd6669-5858-420d-87dd-542d31206daa",
   "metadata": {},
   "source": [
    "## Perform grid search cross-validation and fit the best model to the training data\n",
    "### Select a cross-validation method, ensuring target stratification during validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fc5a3-d429-44ac-87cd-fade73e68154",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d098736-a238-4ddb-9f5e-740cbb372da4",
   "metadata": {},
   "source": [
    "## Exercise 9. Instantiate and fit GridSearchCV to the pipeline\n",
    "Complete the followng code:  \n",
    "```python\n",
    "grid_search = GridSearchCV(..., param_grid, cv=..., scoring='accuracy', verbose=2)  \n",
    "grid_search.fit(..., ...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2fc1e-1ef2-4095-bf0d-d68ca601755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your response.\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', verbose=2)  \n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696d78f-28ad-4af8-8c16-ed03b3c1044a",
   "metadata": {},
   "source": [
    "### Print the best parameters and best crossvalidation score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2091a54-03fd-46ef-9956-d0fdfcb54881",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738c41d-278d-4bf2-b60f-a13be7d24328",
   "metadata": {},
   "source": [
    "## Exercise 10. Display your model's estimated score\n",
    "Complete the followng code:  \n",
    "```python\n",
    "test_score = grid_search.score(..., ...)  \n",
    "print(\"Test set score: {:.2f}\".format(test_score))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc37fa2-eace-4832-8f64-f4701f6ef4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your response.\n",
    "\n",
    "test_score = grid_search.score(X_test, y_test)  \n",
    "print(\"Test set score: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee8ca9-99a7-4cb9-b202-5fce3d9e2d51",
   "metadata": {},
   "source": [
    "So we have a reasonably accurate classifer, which is expected to correctly predict about 84% of the time whether it will rain today in the Melbourne area.  \n",
    "But careful here. Let's take a deeper look at the results.\n",
    "\n",
    "The best model is stored within the gridsearch object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17dbcb6-943f-4a21-a1ef-426887017475",
   "metadata": {},
   "source": [
    "## Exercise 11. Get the model predictions from the grid search estimator on the unseen data\n",
    "Complete the followng code:\n",
    "```python\n",
    "y_pred = grid_search.predict(...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af69aa1-15a1-4ebf-a9a4-1936c4d9c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your response.\n",
    "y_pred = grid_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f14db2-6e67-4d31-9773-cf1c3615b902",
   "metadata": {},
   "source": [
    "## Exercise 12. Print the classification report\n",
    "Complete the followng code:\n",
    "```python\n",
    "print(\"\\nClassification Report:\")\n",
    "print(...(y_test, y_pred))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc1079-4ee8-4f42-b376-05ece11144b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your response.\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c049f02-653b-4486-a748-5efca58a291e",
   "metadata": {},
   "source": [
    "## Exercise 13. Plot the confusion matrix \n",
    "Complete the followng code:\n",
    "```python\n",
    "conf_matrix = ...(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=...)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b2aed-b4e4-4969-865d-dcaefc8ba2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your response.\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67459c1d-cd2f-4439-8b7d-c9d76759022e",
   "metadata": {},
   "source": [
    "Let's consider wether the results indicate a good predictor of rainfall.\n",
    "## Points to note - 2\n",
    "What is the true positive rate? There will be a question on this in the assignment that follows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb3300-7dae-463a-a1b9-fe5e47743864",
   "metadata": {},
   "source": [
    "Based on the confusion matrix shown:\n",
    "- True Positives (TP) = 183\n",
    "- False Negatives (FN) = 175\n",
    "\n",
    "True Positive Rate (TPR) = TP / (TP + FN) = 183 / (183 + 175) = 0.511 or 51.1%\n",
    "\n",
    "This means that when it actually rains, the model correctly predicts rain about 51.1% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59dc211-0e9a-4332-8234-eaf0dd7f62cb",
   "metadata": {},
   "source": [
    "## Feature importances\n",
    "Recall that to obtain the categorical feature importances, we have to work our way backward through the modelling pipeline to associate the feature importances with their original input variables, not the one-hot encoded ones. We don't need to do this for the numeric variables because we didn't modify their names in any way.  \n",
    "Remember we went from categorical features to one-hot encoded features, using the 'cat' column transformer.\n",
    " \n",
    "Let's get all of the feature importances and associate them with their transformed features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b9430-6f69-40ed-bd89-c4eee2912d2d",
   "metadata": {},
   "source": [
    "## Exercise 14. Extract the feature importances\n",
    "Complete the followng code:\n",
    "```python\n",
    "feature_importances = grid_search.best_estimator_['classifier']. ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d73f57-9dba-4c90-9570-ece543f10d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your response.\n",
    "\n",
    "feature_importances = grid_search.best_estimator_['classifier'].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0db25-39f4-4e61-a1f2-0827cf1807c9",
   "metadata": {},
   "source": [
    "Now let's extract the feature importances and plot them as a bar graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429a0b9-441e-4bd4-9f05-6af05c079b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numeric and categorical feature names\n",
    "feature_names = numeric_features + list(grid_search.best_estimator_['preprocessor']\n",
    "                                        .named_transformers_['cat']\n",
    "                                        .named_steps['onehot']\n",
    "                                        .get_feature_names_out(categorical_features))\n",
    "\n",
    "feature_importances = grid_search.best_estimator_['classifier'].feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names,\n",
    "                              'Importance': feature_importances\n",
    "                             }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "N = 20  # Change this number to display more or fewer features\n",
    "top_features = importance_df.head(N)\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names,\n",
    "                              'Importance': feature_importances\n",
    "                             }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature on top\n",
    "plt.title(f'Top {N} Most Important Features in predicting whether it will rain today')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af6176-cabc-43a7-97e8-0ef7bb480174",
   "metadata": {},
   "source": [
    "Based on the feature importance bar graph, Humidity3pm is the most important feature for predicting rainfall, with an importance score of approximately 0.12 (12%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d800c-5d2b-4a75-90c3-a14f2004e495",
   "metadata": {},
   "source": [
    "## Try another model\n",
    "#### Some thoughts.\n",
    "In practice you would want to try out different models and even revisit the data analysis to improve\n",
    "your model's performance. Maybe you can engineer better features, drop irrelevant or redundant ones, project your data onto a dimensional feature space, or impute missing values to be able to use more data. You can also try a larger set of parameters to define you search grid, or even engineer new features using cluster analysis. You can even include the clustering algorithm's hyperparameters in your search grid!\n",
    "\n",
    "With Scikit-learn's powerful pipeline and GridSearchCV classes, this is easy to do in a few steps.\n",
    "\n",
    "## Exercise 15. Update the pipeline and the parameter grid\n",
    "Let's update the pipeline and the parameter grid and train a Logistic Regression model and compare the performance of the two models. You'll need to replace the clasifier with LogisticRegression. We have supplied the parameter grid for you.\n",
    "\n",
    "Complete the following code:\n",
    "```python\n",
    "# Replace RandomForestClassifier with LogisticRegression\n",
    "pipeline.set_params(...=LogisticRegression(random_state=42))\n",
    "\n",
    "# update the model's estimator to use the new pipeline\n",
    "grid_search.estimator = ...\n",
    "\n",
    "# Define a new grid with Logistic Regression parameters\n",
    "param_grid = {\n",
    "    # 'classifier__n_estimators': [50, 100],\n",
    "    # 'classifier__max_depth': [None, 10, 20],\n",
    "    # 'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__solver' : ['liblinear'],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__class_weight' : [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search.param_grid = ...\n",
    "\n",
    "# Fit the updated pipeline with LogisticRegression\n",
    "model.fit(..., ...)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21cc70-f2e7-4d60-808b-bb9914451612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace RandomForestClassifier with LogisticRegression\n",
    "pipeline.set_params(classifier=LogisticRegression(random_state=42))\n",
    "\n",
    "# update the model's estimator to use the new pipeline\n",
    "grid_search.estimator = pipeline\n",
    "\n",
    "# Define a new grid with Logistic Regression parameters\n",
    "param_grid = {\n",
    "    'classifier__solver' : ['liblinear'],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__class_weight' : [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search.param_grid = param_grid\n",
    "\n",
    "# Fit the updated pipeline with LogisticRegression\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109dc2f2-15e5-464e-976d-0bca694c4a76",
   "metadata": {},
   "source": [
    "###  Compare the results to your previous model.\n",
    "Display the clasification report and the confusion matrix for the new model and compare your results with the previous model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc80ed1-6dbe-4918-a12e-668d4f03f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate the confusion matrix \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Titanic Classification Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d22474-2e71-4ec5-b414-4b4ddc33640a",
   "metadata": {},
   "source": [
    "What can you conclude about the model performances? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1d165-7e8b-45fb-967e-27bf0126c1ef",
   "metadata": {},
   "source": [
    "## Points to note - 4\n",
    "Compare the accuracy and true positive rate of rainfall predictions between the LogisticRegression model and the RandomForestClassifier model.\n",
    "\n",
    "**Note: Make sure to provide the answer in the form of a list using either bullets or numbers.**\n",
    "\n",
    "There will be a question on this in the assignment that follows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5d604-5639-47f4-93a4-82773e236321",
   "metadata": {},
   "source": [
    "Comparison between RandomForest and LogisticRegression models:\n",
    "\n",
    "1. Accuracy:\n",
    "   * RandomForest: 84% \n",
    "   * LogisticRegression: 83%\n",
    "   * Both models achieved similar overall accuracy\n",
    "\n",
    "2. True Positive Rate (Recall for \"Yes\" class):\n",
    "   * RandomForest: 51% (183/(183+175))\n",
    "   * LogisticRegression: 50% (182/(182+176)) \n",
    "   * Both models had comparable but relatively low true positive rates\n",
    "\n",
    "Key observations:\n",
    "* RandomForest slightly outperformed LogisticRegression by 1% in accuracy\n",
    "* Both models struggled similarly with predicting rainfall events\n",
    "* The simpler LogisticRegression model achieved competitive performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c9797-3fc8-486a-84d1-55dd79d1331c",
   "metadata": {},
   "source": [
    "\n",
    "### Congratulations! You've made it the end of your final project! \n",
    "Well done! You now have some great tools to use for tackling complex real-world problems with machine learning.\n",
    "\n",
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/jpgrossman/\" target=\"_blank\">Jeff Grossman</a>\n",
    "\n",
    "### Other Contributor(s)\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/abhishek-gagneja-23051987/\" taget=\"_blank\">Abhishek Gagneja</a>\n",
    "\n",
    "<!-- ## Changelog\n",
    "\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|:------------|:------|:------------------|:---------------------------------------|\n",
    "| 2024-11-26 | 0.1  | Jeff Grossman    | Create lab |\n",
    "\n",
    " -->\n",
    "<h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "prev_pub_hash": "aa2e02a19203d80544df6359e40ba175e2a036d3461165d67e6dcc512e1aee52"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
